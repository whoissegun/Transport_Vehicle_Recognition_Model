{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myd60oEosrnM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4y4BCoGt0hG"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzgWRybkt3BI"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/KAGGLE_API_CREDENTIALS/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEgKIJ1at5IK"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLel7uuut6A1"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d abtabm/multiclassimagedatasetairplanecar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCx4KaANuHhQ"
      },
      "outputs": [],
      "source": [
        "!unzip /content/multiclassimagedatasetairplanecar.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB7RIYuIuWRc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from sklearn.metrics import classification_report\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjINIKCa6shE"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomRotation(90),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor()\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder('Dataset/train', transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder('Dataset/test', transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZWhoUDE-A6t"
      },
      "outputs": [],
      "source": [
        "#splitting datasets into batches\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akWA3euS_uut"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dENPkF7LAN7O"
      },
      "outputs": [],
      "source": [
        "class Transport_Vehicle_Recognition(nn.Module):\n",
        "  def __init__(self,input_shape,output_shape):\n",
        "    super().__init__()\n",
        "    self.layers_stack = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=20),\n",
        "        nn.BatchNorm1d(20),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=20, out_features=30),\n",
        "        nn.BatchNorm1d(30),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=30, out_features=16),\n",
        "        nn.BatchNorm1d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=16, out_features=10),\n",
        "        nn.BatchNorm1d(10),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=10,out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,X):\n",
        "    pred_probs = self.layers_stack(X)\n",
        "    return pred_probs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUvXl8IkCb-d"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = 3 * 224 * 224\n",
        "OUTPUT_SHAPE = len(train_dataset.classes)\n",
        "\n",
        "model_0 = Transport_Vehicle_Recognition(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikLbZXveB-RK"
      },
      "outputs": [],
      "source": [
        "#initializing loss function and optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIiWkllUDGTi"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs= 150\n",
        "\n",
        "#train and test loop\n",
        "best_report = None\n",
        "best_model_weights = model_0.state_dict()\n",
        "best_acc = 0.0\n",
        "train_losses  = []\n",
        "test_losses  = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "  epoch_train_loss_sum = 0 #tracks the sum of train losses processed in a single epoch\n",
        "  epoch_train_samples = 0 #tracks the number of samples seen in a single epoch\n",
        "\n",
        "  for X_train,y_train in train_loader:\n",
        "    X_train,y_train = X_train.to(device), y_train.to(device)\n",
        "    y_train_pred = model_0(X_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = loss_fn(y_train_pred, y_train)\n",
        "\n",
        "    epoch_train_loss_sum += train_loss.item() * X_train.size(0) # Accumulate total training loss for the epoch, considering batch sizes.\n",
        "    epoch_train_samples += X_train.size(0) #adds the number of samples in the current batch to epoch_train_samples\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  epoch_avg_loss = epoch_train_loss_sum/epoch_train_samples\n",
        "  train_losses.append(epoch_avg_loss)\n",
        "  if epoch % 5 == 0:\n",
        "    with torch.inference_mode():\n",
        "        model_0.eval()\n",
        "        epoch_trues = [] #stores all targeted labels in a single epoch\n",
        "        epoch_preds = [] #stores all predicted labels in a single epoch\n",
        "        epoch_test_loss = 0\n",
        "        epoch_test_samples = 0\n",
        "        for X_test, y_test in test_loader:\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "            y_test_pred = model_0(X_test)\n",
        "            epoch_trues.extend(list(y_test.cpu().numpy()))\n",
        "            epoch_preds.extend(list(y_test_pred.argmax(dim=1).cpu().numpy()))\n",
        "            test_loss = loss_fn(y_test_pred, y_test)\n",
        "            epoch_test_loss += test_loss.item() * X_test.size(0)\n",
        "            epoch_test_samples += X_test.size(0)\n",
        "\n",
        "        avg_test_loss = epoch_test_loss/epoch_test_samples\n",
        "        test_losses.append(avg_test_loss)\n",
        "\n",
        "\n",
        "        report = classification_report(y_true = epoch_trues,\n",
        "                                       y_pred=epoch_preds,\n",
        "                                       output_dict=True,\n",
        "                                       target_names=test_dataset.classes, zero_division=0)\n",
        "\n",
        "        acc = report['accuracy']\n",
        "        if best_acc < acc:\n",
        "          best_report = report\n",
        "          best_model_weights = copy.deepcopy(model_0.state_dict())\n",
        "\n",
        "  print(epoch)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Train/Test Losses over Epochs\")\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "print(best_report)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJVNZi92GzL7"
      },
      "outputs": [],
      "source": [
        "model_0.load_state_dict(best_model_weights)\n",
        "torch.save(model_0.state_dict(),'Transport_Vehicle_Recognition')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}